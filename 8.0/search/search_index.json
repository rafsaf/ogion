{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ogion","text":""},{"location":"#ogion","title":"Ogion","text":"<p>A tool for performing scheduled database backups and transferring encrypted data to secure public clouds, for home labs, hobby projects, etc., in environments such as k8s, docker, vms.</p> <p>Backups are in <code>age</code> format using age, with strong encryption under the hood. Why age? it's modern replacement for GnuPG, available for most architectures and systems.</p> <p>This project is more or less well tested cron-like runtime with predefined supported providers and backup targets (see below) with sensible defaults for backup commands. It has rich integration tests using providers container replacements: fake gcs, azurite, minio. Goal was to make 100% sure it will work in the wild.</p> <p>Starting from version 8.0, lzip compression is used before encryption step. While mixing compression with encryption can be dangerous in some scenarios, <code>lzip</code> is used here, because it operates on fixed-size blocks, making it resistant to compression side-channel attacks.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>https://ogion.rafsaf.pl</li> </ul>"},{"location":"#alternatives","title":"Alternatives","text":"<p>There are better tools for bigger databases like pgBackRest - Reliable PostgreSQL Backup &amp; Restore.</p>"},{"location":"#supported-backup-targets","title":"Supported backup targets","text":"<ul> <li>PostgreSQL (all currently supported versions)</li> <li>MariaDB (all currently supported versions)</li> <li>MySQL (all currently supported versions)</li> <li>Single file</li> <li>Directory</li> </ul>"},{"location":"#supported-upload-providers","title":"Supported upload providers","text":"<ul> <li>Google Cloud Storage bucket</li> <li>S3 storage compatibile bucket (AWS, Minio)</li> <li>Azure Blob Storage</li> <li>Debug (local)</li> </ul>"},{"location":"#notifications","title":"Notifications","text":"<ul> <li>Discord</li> <li>Email (SMTP)</li> <li>Slack</li> </ul>"},{"location":"#deployment-strategies","title":"Deployment strategies","text":"<p>Using docker image: <code>rafsaf/ogion:latest</code>, see all tags on dockerhub</p> <ul> <li>docker (docker compose) container</li> <li>kubernetes deployment</li> </ul>"},{"location":"#architectures","title":"Architectures","text":"<ul> <li>linux/amd64</li> <li>linux/arm64</li> </ul>"},{"location":"#example","title":"Example","text":"<p>Everyday 5am backup of PostgreSQL database defined in the same file and running in docker container.</p> <pre><code># docker-compose.yml\n\nservices:\n  db:\n    image: postgres:17\n    environment:\n      - POSTGRES_PASSWORD=pwd\n  ogion:\n    image: rafsaf/ogion:latest\n    environment:\n      - POSTGRESQL_DB_README=host=db password=pwd cron_rule=0 0 5 * * port=5432\n      - AGE_RECIPIENTS=age1q5g88krfjgty48thtctz22h5ja85grufdm0jly3wll6pr9f30qsszmxzm2\n      - BACKUP_PROVIDER=name=debug\n</code></pre> <p>(NOTE this will use provider debug that store backups locally in the container).</p>"},{"location":"#real-world-usage","title":"Real world usage","text":"<p>The author actively uses ogion (with GCS) for one production project plemiona-planer.pl postgres database (both PRD and STG) and for bunch of homelab projects including self hosted Firefly III mariadb, Grafana postgres, KeyCloak postgres, Nextcloud postgres and configuration file, Minecraft server files, and two other postgres dbs for some demo projects.</p> <p>See how it looks for ~2GB size database:</p> <p></p> <p> </p>"},{"location":"configuration/","title":"Configuration","text":"<p>Environemt variables</p> Name Type Description Default AGE_RECIPIENTS string[required] AGE public keys. Can be many splitted by comma. Note those must be public keys. Keep you private keys safe. - BACKUP_PROVIDER string[required] See <code>Providers</code> chapter, choosen backup provider for example GCS. - INSTANCE_NAME string Name of this ogion instance, will be used for example when sending fail messages. Defaults to system hostname. system hostname BACKUP_MAX_NUMBER int Soft limit how many backups can live at once for backup target. Defaults to <code>7</code>. This must makes sense with cron expression you use. For example if you want to have <code>7</code> day retention, and make backups at 5:00, <code>max_backups=7</code> is fine, but if you make <code>4</code> backups per day, you would need <code>max_backups=28</code>. Limit is soft and can be exceeded if no backup is older than value specified in <code>min_retention_days</code> in backup target. Note this global default and can be overwritten by using <code>max_backups</code> param in specific targets. Min <code>1</code> and max <code>998</code>. 7 BACKUP_MIN_RETENTION_DAYS int Hard minimum backups lifetime in days. Ogion won't ever delete files before, regardles of other options. Note this global default and can be overwritten by using <code>min_retention_days</code> param in specific targets. Min <code>0</code> and max <code>36600</code>. 3 POSTGRESQL_... backup target syntax PostgreSQL database target, see PostgreSQL. - MARIADB_... backup target syntax MariaDB database target, see MariaDB. - SINGLEFILE_... backup target syntax Single file database target, see Single file. - DIRECTORY_... backup target syntax Directory database target, see Directory. - LZIP_LEVEL int Compression level for LZIP (0-9). Higher values mean better compression but slower speed. 0 LZIP_THREADS int Number of threads for LZIP compression (1-1024). 1 DISCORD_WEBHOOK_URL http url Webhook URL for fail messages. - DISCORD_MAX_MSG_LEN int Maximum length of messages send to discord API. Sensible default used. Min <code>150</code> and max <code>10000</code>. 1500 SLACK_WEBHOOK_URL http url Webhook URL for fail messages. - SLACK_MAX_MSG_LEN int Maximum length of messages send to slack API. Sensible default used. Min <code>150</code> and max <code>10000</code>. 1500 SMTP_HOST string SMTP server host. - SMTP_FROM_ADDR string Email address that will send emails. - SMTP_PASSWORD string Password for <code>SMTP_FROM_ADDR</code>. - SMTP_TO_ADDRS string Comma separated list of email addresses to send emails. For example <code>email1@example.com,email2@example.com</code>. - SMTP_PORT int SMTP server port. 587 LOG_LEVEL string Case sensitive const log level, must be one of <code>INFO</code>, <code>DEBUG</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>. INFO SUBPROCESS_TIMEOUT_SECS int Indicates how long subprocesses can last. Note that all backups are run from shell in subprocesses. Defaults to 3600 seconds which should be enough for even big dbs to make backup of. Min <code>5</code> and max <code>86400</code> (24h). 3600 SIGTERM_TIMEOUT_SECS int Time in seconds on exit how long ogion will wait for ongoing backup threads before force killing them and exiting. Min <code>0</code> and max <code>86400</code> (24h). 3600 OGION_CPU_ARCHITECTURE string CPU architecture, supported <code>amd64</code> and <code>arm64</code>. Docker container will set it automatically so probably do not change it. null DEBUG_AGE_SECRET_KEY string AGE single secret key used to automatically decrypt when using <code>--restore</code> or <code>--restore-latest</code> command without asking for it in input. Only for debug, tests or when you know what you are doing. amd64 <p> </p>"},{"location":"deployment/","title":"Deployment","text":"<p>In general, use docker image <code>rafsaf/ogion</code> (here available tags on dockerhub), it supports both <code>amd64</code> and <code>arm64</code> architectures. Standard way would be to run it with docker compose or as a kubernetes deployment. If not sure, use <code>latest</code>.</p>"},{"location":"deployment/#docker-compose","title":"Docker Compose","text":""},{"location":"deployment/#docker-compose-file","title":"Docker compose file","text":"<pre><code># docker-compose.yml\n\nservices:\n  ogion:\n    container_name: ogion\n    image: rafsaf/ogion:latest\n    environment:\n      - POSTGRESQL_DB1=...\n      - MARIADB_DB2=...\n\n      - AGE_RECIPIENTS=age1q5g88krfjgty48thtctz22h5ja85grufdm0jly3wll6pr9f30qsszmxzm2\n      - BACKUP_PROVIDER=name=gcs bucket_name=my_bucket_name bucket_upload_path=my_ogion_instance_1 service_account_base64=Z29vZ2xlX3NlcnZpY2VfYWNjb3VudAo=\n</code></pre>"},{"location":"deployment/#notes","title":"Notes","text":"<ul> <li>For hard debug you can set <code>LOG_LEVEL=DEBUG</code> and use (container name is ogion):   <pre><code>docker logs ogion\n</code></pre></li> <li>There is runtime flag <code>--single</code> that ignores cron, make all databases backups and exits. To use it when having already running container, use:   <pre><code>docker compose run --rm ogion python -m ogion.main --single\n</code></pre>   BE CAREFUL, if your setup if fine, this will upload backup files to cloud provider, so costs may apply.</li> <li>There is runtime flag <code>--debug-notifications</code> that setup notifications, raise dummy exception and exits. This can help ensure notifications are working:   <pre><code>docker compose run --rm ogion python -m ogion.main --debug-notifications\n</code></pre></li> </ul>"},{"location":"deployment/#kubernetes","title":"Kubernetes","text":"<pre><code># ogion-deployment.yml\n\nkind: Namespace\napiVersion: v1\nmetadata:\n  name: ogion\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: ogion-secrets\n  namespace: ogion\ntype: Opaque\nstringData:\n  POSTGRESQL_DB1: ...\n  MARIADB_DB2: ...\n  AGE_RECIPIENTS: age1q5g88krfjgty48thtctz22h5ja85grufdm0jly3wll6pr9f30qsszmxzm2\n  BACKUP_PROVIDER: \"name=gcs bucket_name=my_bucket_name bucket_upload_path=my_ogion_instance_1 service_account_base64=Z29vZ2xlX3NlcnZpY2VfYWNjb3VudAo=\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ogion\n  name: ogion\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ogion\n  template:\n    metadata:\n      labels:\n        app: ogion\n    spec:\n      containers:\n        - image: rafsaf/ogion:latest\n          name: ogion\n          envFrom:\n            - secretRef:\n                name: ogion-secrets\n</code></pre>"},{"location":"deployment/#notes_1","title":"Notes","text":"<ul> <li>For hard debug you can set <code>LOG_LEVEL: DEBUG</code> and use (for brevity random pod name used):   <pre><code>kubectl logs ogion-9c8b8b77d-z5xsc -n ogion\n</code></pre></li> <li>There is runtime flag <code>--single</code> that ignores cron, make all databases backups and exits. To use it when having already running container, use:   <pre><code>kubectl exec --it ogion-9c8b8b77d-z5xsc -n ogion -- python -m ogion.main --single\n</code></pre>   BE CAREFUL, if your setup if fine, this will upload backup files to cloud provider, so costs may apply.</li> <li>There is runtime flag <code>--debug-notifications</code> that setup notifications, raise dummy exception and exits. This can help ensure notifications are working:   <pre><code>kubectl exec --it ogion-9c8b8b77d-z5xsc -n ogion -- python -m ogion.main --debug-notifications\n</code></pre> </li> </ul>"},{"location":"disaster_recovery/","title":"Disaster recovery using ogion image","text":"<p>For it to work, you must have list and read access to your cloud provider (eg GCS, S3, etc.) in service account on credentials that are using inside ogion container.</p> <p>The container has following commands available:</p> <pre><code>usage: main.py [-h] [-s] [-n] [--debug-download DEBUG_DOWNLOAD] [--target TARGET]\n               [--restore-latest] [-r RESTORE] [-l]\n\nOgion program\n\noptions:\n  -h, --help            show this help message and exit\n  -s, --single          Only single backup then exit\n  -n, --debug-notifications\n                        Check if notifications setup is working\n  --debug-download DEBUG_DOWNLOAD\n                        Download given backup file locally and print path\n  --target TARGET       Backup target\n  --restore-latest      Restore given target to latest database\n  -r, --restore RESTORE\n                        Restore given target to backup file\n  -l, --list            List all backups for given target\n</code></pre> <p>To eg. restore to the latest point for example backup target <code>postgresql_my-instance</code> you can use:</p> <ul> <li>k8s: <code>kubectl exec --it ogion-9c8b8b77d-z5xsc -n ogion -- python -m ogion.main --target postgresql_my-instance --restore-latest</code></li> <li>docker: <code>docker compose run --rm ogion python -m ogion.main --target postgresql_my-instance --restore-latest</code></li> </ul> <p>PS. In the process, prgram will ask for age secret key in input.</p>"},{"location":"manual_disaster_recovery/","title":"How to restore manually","text":"<p>To restore backups you already have in cloud, for sure you will need <code>age</code> to extract the archive (and of course you age private key matching one of those in <code>AGE_RECIPIENTS</code> used for creating it in a first place). That step is ommited below.</p> <p>For below databases restore, you can for sure use <code>ogion</code> image itself see Disaster recovery</p> <p>Other idea if you feel unhappy with passing your database backups around (even if password protected) would be to make the backup file public for a moment and available to download and use tools like <code>curl</code> to download it on destination place. If leaked, there is yet very strong cryptography to protect you. This should be sufficient for bunch of projects.</p>"},{"location":"manual_disaster_recovery/#directory-and-single-file","title":"Directory and single file","text":"<p>Just file or directory, copy them back where you want.</p>"},{"location":"manual_disaster_recovery/#postgresql","title":"PostgreSQL","text":"<p>Backup is made using <code>pg_dump</code> (see def _backup() params). To restore database, you will need <code>psql</code> https://www.postgresql.org/docs/current/app-psql.html and network access to database. If on debian/ubuntu, this is provided by apt package <code>postgresql-client</code>.</p> <p>Follow docs (ogion creates typical SQL file backups, nothing special about them), but command will look something like that:</p> <pre><code>psql -h localhost -p 5432 -U postgres database_name -W &lt; backup_file.sql\n</code></pre>"},{"location":"manual_disaster_recovery/#mariadb","title":"MariaDB","text":"<p>Backup is made using <code>mariadb-dump</code> (see def _backup() params). To restore database, you will need <code>mariadb</code> https://mariadb.com/kb/en/mariadb-command-line-client/ and network access to database. If on debian/ubuntu, this is provided by apt package https://mariadb.com/kb/en/mariadb-package-repository-setup-and-usage/.</p> <p>Follow docs (ogion creates typical SQL file backups, nothing special about them), but command will look something like that:</p> <pre><code>mariadb -h localhost -P 3306 -u root -p database_name &lt; backup_file.sql\n</code></pre> <p> </p>"},{"location":"backup_targets/directory/","title":"Directory","text":""},{"location":"backup_targets/directory/#environment-variable","title":"Environment variable","text":"<pre><code>DIRECTORY_SOME_STRING=\"abs_path=... cron_rule=...\"\n</code></pre> <p>Note</p> <p>Any environment variable that starts with \"DIRECTORY_\" will be handled as Directory. There can be multiple files paths definition for one ogion instance, for example <code>DIRECTORY_FOO</code> and <code>DIRECTORY_BAR</code>. Params must be included in value, splited by single space for example <code>\"value1=1 value2=foo\"</code>.</p>"},{"location":"backup_targets/directory/#params","title":"Params","text":"Name Type Description Default abs_path string[requried] Absolute path to folder for backup. - cron_rule string[requried] Cron expression for backups, see https://crontab.guru/ for help. - max_backups int Soft limit how many backups can live at once for backup target. Defaults to <code>7</code>. This must makes sense with cron expression you use. For example if you want to have <code>7</code> day retention, and make backups at 5:00, <code>max_backups=7</code> is fine, but if you make <code>4</code> backups per day, you would need <code>max_backups=28</code>. Limit is soft and can be exceeded if no backup is older than value specified in min_retention_days. Min <code>1</code> and max <code>998</code>. Defaults to enviornment variable BACKUP_MAX_NUMBER, see Configuration. BACKUP_MAX_NUMBER min_retention_days int Hard minimum backups lifetime in days. Ogion won't ever delete files before, regardles of other options. Min <code>0</code> and max <code>36600</code>. Defaults to enviornment variable BACKUP_MIN_RETENTION_DAYS, see Configuration. BACKUP_MIN_RETENTION_DAYS"},{"location":"backup_targets/directory/#examples","title":"Examples","text":"<pre><code># 1. Directory /home/user/folder with backup every single minute\nDIRECTORY_FIRST='abs_path=/home/user/folder cron_rule=* * * * *'\n\n# 2. Directory /etc with backup on every night (UTC) at 05:00\nDIRECTORY_SECOND='abs_path=/etc cron_rule=0 5 * * *'\n\n# 3. Mounted directory /mnt/homedir with backup on every 6 hours at '15 with max number of backups of 20\nDIRECTORY_HOME_DIR='abs_path=/mnt/homedir cron_rule=15 */3 * * * max_backups=20'\n</code></pre>"},{"location":"backup_targets/file/","title":"Single file","text":""},{"location":"backup_targets/file/#environment-variable","title":"Environment variable","text":"<pre><code>SINGLEFILE_SOME_STRING=\"abs_path=... cron_rule=...\"\n</code></pre> <p>Note</p> <p>Any environment variable that starts with \"SINGLEFILE_\" will be handled as Single File. There can be multiple files paths definition for one ogion instance, for example <code>SINGLEFILE_FOO</code> and <code>SINGLEFILE_BAR</code>. Params must be included in value, splited by single space for example <code>\"value1=1 value2=foo\"</code>.</p>"},{"location":"backup_targets/file/#params","title":"Params","text":"Name Type Description Default abs_path string[requried] Absolute path to file for backup. - cron_rule string[requried] Cron expression for backups, see https://crontab.guru/ for help. - max_backups int Soft limit how many backups can live at once for backup target. Defaults to <code>7</code>. This must makes sense with cron expression you use. For example if you want to have <code>7</code> day retention, and make backups at 5:00, <code>max_backups=7</code> is fine, but if you make <code>4</code> backups per day, you would need <code>max_backups=28</code>. Limit is soft and can be exceeded if no backup is older than value specified in min_retention_days. Min <code>1</code> and max <code>998</code>. Defaults to enviornment variable BACKUP_MAX_NUMBER, see Configuration. BACKUP_MAX_NUMBER min_retention_days int Hard minimum backups lifetime in days. Ogion won't ever delete files before, regardles of other options. Min <code>0</code> and max <code>36600</code>. Defaults to enviornment variable BACKUP_MIN_RETENTION_DAYS, see Configuration. BACKUP_MIN_RETENTION_DAYS"},{"location":"backup_targets/file/#examples","title":"Examples","text":"<pre><code># File /home/user/file.txt with backup every single minute\nSINGLEFILE_FIRST='abs_path=/home/user/file.txt cron_rule=* * * * *'\n\n# File /etc/hosts with backup on every night (UTC) at 05:00\nSINGLEFILE_SECOND='abs_path=/etc/hosts cron_rule=0 5 * * *'\n\n# File config.json in mounted dir /mnt/appname with backup on every 6 hours at '15 with max number of backups of 20\nSINGLEFILE_THIRD='abs_path=/mnt/appname/config.json cron_rule=15 */3 * * * max_backups=20'\n</code></pre>"},{"location":"backup_targets/mariadb/","title":"MariaDB","text":""},{"location":"backup_targets/mariadb/#environment-variable","title":"Environment variable","text":"<pre><code>MARIADB_SOME_STRING=\"host=... password=... cron_rule=...\"\n</code></pre> <p>Note</p> <p>Any environment variable that starts with \"MARIADB_\" will be handled as MariaDB. There can be multiple files paths definition for one ogion instance, for example <code>MARIADB_FOO_MY_DB1</code> and <code>MARIADB_BAR_MY_DB2</code>. All currently supported versions are also supported by ogion. Params must be included in value, splited by single space for example <code>\"value1=1 value2=foo\"</code>.</p>"},{"location":"backup_targets/mariadb/#params","title":"Params","text":"Name Type Description Default password string[requried] Mariadb database password. - cron_rule string[requried] Cron expression for backups, see https://crontab.guru/ for help. - user string Mariadb database username. root host string Mariadb database hostname. localhost port int Mariadb database port. 3306 db string Mariadb database name. mariadb max_backups int Soft limit how many backups can live at once for backup target. Defaults to <code>7</code>. This must makes sense with cron expression you use. For example if you want to have <code>7</code> day retention, and make backups at 5:00, <code>max_backups=7</code> is fine, but if you make <code>4</code> backups per day, you would need <code>max_backups=28</code>. Limit is soft and can be exceeded if no backup is older than value specified in min_retention_days. Min <code>1</code> and max <code>998</code>. Defaults to enviornment variable BACKUP_MAX_NUMBER, see Configuration. BACKUP_MAX_NUMBER min_retention_days int Hard minimum backups lifetime in days. Ogion won't ever delete files before, regardles of other options. Min <code>0</code> and max <code>36600</code>. Defaults to enviornment variable BACKUP_MIN_RETENTION_DAYS, see Configuration. BACKUP_MIN_RETENTION_DAYS"},{"location":"backup_targets/mariadb/#additional-connection-client-params","title":"Additional connection client params","text":"<p>Extra variables that starts with <code>client_</code> will be passed AS IS to mariadb command underthehood as escaped lines in client section of <code>.cnf</code> configuration file, see https://mariadb.com/kb/en/mariadb-command-line-client:</p> <p>For example you can use it for SSL setup:</p> <ul> <li><code>client_ssl=true</code></li> <li><code>client_ssl-ca=path1</code></li> <li><code>client_ssl-cert=path2</code></li> <li><code>client_ssl-key=path3</code></li> </ul>"},{"location":"backup_targets/mariadb/#examples","title":"Examples","text":"<pre><code># 1. Local MariaDB with backup every single minute\nMARIADB_FIRST_DB='host=localhost port=3306 password=secret cron_rule=* * * * *'\n\n# 2. MariaDB in local network with backup on every night (UTC) at 05:00\nMARIADB_SECOND_DB='host=10.0.0.1 port=3306 user=foo password=change_me! db=bar cron_rule=0 5 * * *'\n\n# 3. MariaDB in local network with backup on every 6 hours at '15 with max number of backups of 20\nMARIADB_THIRD_DB='host=192.168.1.5 port=3306 user=root password=change_me_please! db=project cron_rule=15 */3 * * * max_backups=20'\n\n# 4. MariaDB local database above 11.3 with ssl-verify-server-cert disabled\nMARIADB_4_DB='host=localhost port=3306 password=secret cron_rule=* * * * * client_ssl-verify-server-cert=false'\n\n# 5. MariaDB with ssl disabled using skip-ssl\nMARIADB_5_DB='host=localhost port=3306 password=secret cron_rule=* * * * * client_skip-ssl=true'\n</code></pre>"},{"location":"backup_targets/mysql/","title":"MySQL","text":"<p>Please use MariaDB backup target.</p> <p> </p>"},{"location":"backup_targets/postgresql/","title":"PostgreSQL","text":""},{"location":"backup_targets/postgresql/#environment-variable","title":"Environment variable","text":"<pre><code>POSTGRESQL_SOME_STRING=\"host=... password=... cron_rule=...\"\n</code></pre> <p>Note</p> <p>Any environment variable that starts with \"POSTGRESQL_\" will be handled as PostgreSQL. There can be multiple files paths definition for one ogion instance, for example <code>POSTGRESQL_FOO_MY_DB1</code> and <code>POSTGRESQL_BAR_MY_DB2</code>. All currently supported versions are also supported by ogion. Changes in versions are automatically tracke . Params must be included in value, splited by single space for example <code>\"value1=1 value2=foo\"</code>.</p>"},{"location":"backup_targets/postgresql/#params","title":"Params","text":"Name Type Description Default password string[requried] PostgreSQL database password. - cron_rule string[requried] Cron expression for backups, see https://crontab.guru/ for help. - user string PostgreSQL database username. postgres host string PostgreSQL database hostname. localhost port int PostgreSQL database port. 5432 db string PostgreSQL database name. postgres max_backups int Soft limit how many backups can live at once for backup target. Defaults to <code>7</code>. This must makes sense with cron expression you use. For example if you want to have <code>7</code> day retention, and make backups at 5:00, <code>max_backups=7</code> is fine, but if you make <code>4</code> backups per day, you would need <code>max_backups=28</code>. Limit is soft and can be exceeded if no backup is older than value specified in min_retention_days. Min <code>1</code> and max <code>998</code>. Defaults to enviornment variable BACKUP_MAX_NUMBER, see Configuration. BACKUP_MAX_NUMBER min_retention_days int Hard minimum backups lifetime in days. Ogion won't ever delete files before, regardles of other options. Min <code>0</code> and max <code>36600</code>. Defaults to enviornment variable BACKUP_MIN_RETENTION_DAYS, see Configuration. BACKUP_MIN_RETENTION_DAYS"},{"location":"backup_targets/postgresql/#additional-connection-params","title":"Additional connection params","text":"<p>Extra variables that starts with <code>conn_</code> will be passed AS IS to psql command underthehood as url-encoded connection params:</p> <p>For example you can use it for SSL setup:</p> <ul> <li><code>conn_sslmode=verify-ca</code></li> <li><code>conn_sslrootcert=path-to-mounted-server-ca-file</code></li> <li><code>conn_sslcert=path-to-mounted-client-ca-file</code></li> <li><code>conn_sslkey=path-to-mounted-client-key-file</code></li> </ul>"},{"location":"backup_targets/postgresql/#examples","title":"Examples","text":"<pre><code># 1. Local PostgreSQL with backup every single minute\nPOSTGRESQL_FIRST_DB='host=localhost port=5432 password=secret cron_rule=* * * * *'\n\n# 2. PostgreSQL in local network with backup on every night (UTC) at 05:00\nPOSTGRESQL_SECOND_DB='host=10.0.0.1 port=5432 user=foo password=change_me! db=bar cron_rule=0 5 * * *'\n\n# 3. PostgreSQL in local network with backup on every 6 hours at '15 with max number of backups of 20\nPOSTGRESQL_THIRD_DB='host=192.168.1.5 port=5432 user=root password=change_me_please! db=project cron_rule=15 */3 * * * max_backups=20'\n\n# 4. PostgreSQL connected using sslmode require\nPOSTGRESQL_4_DB_SSL='host=localhost port=5432 password=secret cron_rule=* * * * * conn_sslmode=require'\n</code></pre>"},{"location":"notifications/discord/","title":"Discord","text":"<p>It is possible to send messages to your Discord channels in events of failed backups.</p> <p>Integration is via Discord webhooks and environment variables.</p> <p>Follow their documentation https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks.</p> <p>You should be able to generate webhooks like <code>\"https://discord.com/api/webhooks/1111111111/some-long-token\"</code>.</p>"},{"location":"notifications/discord/#environemt-variables","title":"Environemt variables","text":"Name Type Description Default DISCORD_WEBHOOK_URL http url Webhook URL for fail messages. - DISCORD_MAX_MSG_LEN int Maximum length of messages send to discord API. Sensible default used. Min <code>150</code> and max <code>10000</code>. 1500"},{"location":"notifications/discord/#examples","title":"Examples:","text":"<pre><code>DISCORD_WEBHOOK_URL=\"https://discord.com/api/webhooks/1111111111/long-token\"\n</code></pre>"},{"location":"notifications/slack/","title":"Slack","text":"<p>It is possible to send messages to your Slack channels in events of failed backups.</p> <p>Integration is via Slack webhooks and environment variables.</p> <p>Follow their documentation https://api.slack.com/messaging/webhooks#create_a_webhook.</p> <p>You should be able to generate webhooks like <code>\"https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX\"</code>.</p>"},{"location":"notifications/slack/#environemt-variables","title":"Environemt variables","text":"Name Type Description Default SLACK_WEBHOOK_URL http url Webhook URL for fail messages. - SLACK_MAX_MSG_LEN int Maximum length of messages send to slack API. Sensible default used. Min <code>150</code> and max <code>10000</code>. 1500"},{"location":"notifications/slack/#examples","title":"Examples:","text":"<pre><code>SLACK_WEBHOOK_URL=\"https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX\"\n</code></pre>"},{"location":"notifications/smtp/","title":"Email (SMTP)","text":"<p>It is possible to send messages via email using SMTP protocol. Implementation uses STARTTLS so be sure you mail server support it. For technical details refer to https://docs.python.org/3/library/smtplib.html.</p> <p>Note, when any of params <code>SMTP_HOST</code>, <code>SMTP_FROM_ADDR</code>, <code>SMTP_PASSWORD</code>, <code>SMTP_TO_ADDRS</code>  is set, all are required. If not provided, execption will be raised.</p>"},{"location":"notifications/smtp/#environemt-variables","title":"Environemt variables","text":"Name Type Description Default SMTP_HOST string[required] SMTP server host. - SMTP_FROM_ADDR string[required] Email address that will send emails. - SMTP_PASSWORD string[required] Password for <code>SMTP_FROM_ADDR</code>. - SMTP_TO_ADDRS string[required] Comma separated list of email addresses to send emails. For example <code>email1@example.com,email2@example.com</code>. - SMTP_PORT int SMTP server port. 587"},{"location":"notifications/smtp/#examples","title":"Examples:","text":"<pre><code>SMTP_HOST=\"pro2.mail.ovh.net\"\nSMTP_FROM_ADDR=\"test@example.com\"\nSMTP_PASSWORD=\"changeme\"\nSMTP_TO_ADDRS=\"me@example.com,other@example.com\"\nSMTP_PORT=587\n</code></pre>"},{"location":"providers/azure/","title":"Azure Blob Storage","text":""},{"location":"providers/azure/#environment-variable","title":"Environment variable","text":"<pre><code>BACKUP_PROVIDER=\"name=azure container_name=my-ogion-instance connect_string=DefaultEndpointsProtocol=https;AccountName=accname;AccountKey=secret;EndpointSuffix=core.windows.net\"\n</code></pre> <p>Uses Azure Blob Storage for storing backups.</p> <p>Note</p> <p>There can be only one upload provider defined per app, using BACKUP_PROVIDER environemnt variable. It's type is guessed by using <code>name</code>, in this case <code>name=azure</code>. Params must be included in value, splited by single space for example \"value1=1 value2=foo\".</p>"},{"location":"providers/azure/#params","title":"Params","text":"Name Type Description Default name string[requried] Must be set literaly to string <code>azure</code> to use Azure. - container_name string[requried] Storage account container name. It must be already created, ogion won't create new container. - connect_string string[requried] Connection string copied from your storage account \"Access keys\" section. -"},{"location":"providers/azure/#examples","title":"Examples","text":"<pre><code># 1. Storage account accname and container name my-ogion-instance\nBACKUP_PROVIDER=\"name=azure container_name=my-ogion-instance connect_string=DefaultEndpointsProtocol=https;AccountName=accname;AccountKey=secret;EndpointSuffix=core.windows.net\"\n\n# 2. Storage account birds and container name birds\nBACKUP_PROVIDER=\"name=azure container_name=birds connect_string=DefaultEndpointsProtocol=https;AccountName=birds;AccountKey=secret;EndpointSuffix=core.windows.net\"\n</code></pre>"},{"location":"providers/azure/#resources","title":"Resources","text":""},{"location":"providers/azure/#creating-azure-storage-account","title":"Creating azure storage account","text":"<p>https://learn.microsoft.com/en-us/azure/storage/common/storage-account-create?tabs=azure-portal</p> <p> </p>"},{"location":"providers/debug/","title":"Debug","text":""},{"location":"providers/debug/#environment-variable","title":"Environment variable","text":"<pre><code>BACKUP_PROVIDER=\"name=debug\"\n</code></pre> <p>Uses only local files (folder inside container) for storing backup. This is meant only for debug purposes.</p> <p>If you absolutely must not upload backups to outside world, consider adding some persistant volume for folder where buckups live in the container, that is <code>/var/lib/ogion/data</code>.</p> <p>Note</p> <p>There can be only one upload provider defined per app, using BACKUP_PROVIDER environemnt variable. It's type is guessed by using <code>name</code>, in this case <code>name=debug</code>.</p>"},{"location":"providers/debug/#params","title":"Params","text":"Name Type Description Default name string[requried] Must be set literaly to string <code>debug</code> to use Debug. -"},{"location":"providers/debug/#examples","title":"Examples","text":"<pre><code># 1. Debug provider\nBACKUP_PROVIDER='name=debug'\n</code></pre>"},{"location":"providers/google_cloud_storage/","title":"Google Cloud Storage","text":""},{"location":"providers/google_cloud_storage/#environment-variable","title":"Environment variable","text":"<pre><code>BACKUP_PROVIDER=\"name=gcs bucket_name=my_bucket_name bucket_upload_path=my_ogion_instance_1 service_account_base64=Z29vZ2xlX3NlcnZpY2VfYWNjb3VudAo=\"\n</code></pre> <p>Uses Google Cloud Storage bucket for storing backups.</p> <p>Note</p> <p>There can be only one upload provider defined per app, using BACKUP_PROVIDER environemnt variable. It's type is guessed by using <code>name</code>, in this case <code>name=gcs</code>. Params must be included in value, splited by single space for example \"value1=1 value2=foo\".</p>"},{"location":"providers/google_cloud_storage/#params","title":"Params","text":"Name Type Description Default name string[requried] Must be set literaly to string <code>gcs</code> to use Google Cloud Storage. - bucket_name string[requried] Your globally unique bucket name. - bucket_upload_path string[requried] Prefix that every created backup will have, for example if it is equal to <code>my_ogion_instance_1</code>, paths to backups will look like <code>my_ogion_instance_1/your_backup_target_eg_postgresql/file123.age</code>. Usually this should be something unique for this ogion instance, for example <code>k8s_foo_ogion</code>. - service_account_base64 string[requried] Base64 JSON service account file created in IAM, with write and read access permissions to bucket, see Resources below. - chunk_size_mb int The size of a chunk of data transfered to GCS, consider lower value only if for example your internet connection is slow or you know what you are doing, 100MB is google default. 100 chunk_timeout_secs int The chunk of data transfered to GCS upload timeout, consider higher value only if for example your internet connection is slow or you know what you are doing, 60s is google default. 60"},{"location":"providers/google_cloud_storage/#examples","title":"Examples","text":"<pre><code># 1. Bucket pets-bucket\nBACKUP_PROVIDER='name=gcs bucket_name=pets-bucket bucket_upload_path=pets_ogion service_account_base64=Z29vZ2xlX3NlcnZpY2VfYWNjb3VudAo='\n\n# 2. Bucket birds with smaller chunk size\nBACKUP_PROVIDER='name=gcs bucket_name=birds bucket_upload_path=birds_ogion chunk_size_mb=25 chunk_timeout_secs=120 service_account_base64=Z29vZ2xlX3NlcnZpY2VfYWNjb3VudAo='\n</code></pre>"},{"location":"providers/google_cloud_storage/#resources","title":"Resources","text":""},{"location":"providers/google_cloud_storage/#creating-bucket","title":"Creating bucket","text":"<p>https://cloud.google.com/storage/docs/creating-buckets</p>"},{"location":"providers/google_cloud_storage/#creating-service-account","title":"Creating service account","text":"<p>https://cloud.google.com/iam/docs/service-accounts-create</p>"},{"location":"providers/google_cloud_storage/#giving-it-required-roles-to-service-account","title":"Giving it required roles to service account","text":"<ol> <li> <p>Go \"IAM and admin\" -&gt; \"IAM\"</p> </li> <li> <p>Find your service account and update its roles</p> </li> </ol> <p>Give it following roles so it will have read access for whole bucket \"my_bucket_name\" and admin access for only path prefix \"my_ogion_instance_1\" in bucket \"my_bucket_name\":</p> <ol> <li>Storage Object Admin (with IAM condition: NAME starts with <code>projects/_/buckets/my_bucket_name/objects/my_ogion_instance_1</code>)</li> <li>Storage Object Viewer (with IAM condition: NAME starts with <code>projects/_/buckets/my_bucket_name</code>)</li> </ol> <p>After sucessfully creating service account, create new private key with JSON type and download it. File similar to <code>your_project_name-03189413be28.json</code> will appear in your Downloads.</p> <p>To get base64 (without any new lines) from it, use command:</p> <pre><code>cat your_project_name-03189413be28.json | base64 -w 0\n</code></pre>"},{"location":"providers/google_cloud_storage/#terraform","title":"Terraform","text":"<p>If using terraform for managing cloud infra, Service Accounts definition can be following:</p> <pre><code>resource \"google_service_account\" \"ogion-my_ogion_instance_1\" {\n  account_id   = \"ogion-my_ogion_instance_1\"\n  display_name = \"SA my_ogion_instance_1 for ogion bucket access\"\n}\n\nresource \"google_project_iam_member\" \"ogion-my_ogion_instance_1-iam-object-admin\" {\n  project = local.project_id\n  role    = \"roles/storage.objectAdmin\"\n  member  = \"serviceAccount:${google_service_account.ogion-my_ogion_instance_1.email}\"\n  condition {\n    title      = \"object_admin_only_ogion_bucket_specific_path\"\n    expression = \"resource.name.startsWith(\\\"projects/_/buckets/my_bucket_name/objects/my_ogion_instance_1\\\")\"\n  }\n}\nresource \"google_project_iam_member\" \"ogion-my_ogion_instance_1-iam-object-viewer\" {\n  project = local.project_id\n  role    = \"roles/storage.objectViewer\"\n  member  = \"serviceAccount:${google_service_account.ogion-my_ogion_instance_1.email}\"\n\n  condition {\n    title      = \"object_viewer_only_ogion_bucket\"\n    expression = \"resource.name.startsWith(\\\"projects/_/buckets/my_bucket_name\\\")\"\n  }\n}\n</code></pre> <p> </p>"},{"location":"providers/s3/","title":"S3","text":""},{"location":"providers/s3/#environment-variable","title":"Environment variable","text":"<pre><code>BACKUP_PROVIDER=\"name=s3 bucket_name=my_bucket_name bucket_upload_path=my_ogion_instance_1 access_key=AKIAU5JB5UQDL8C3K6UP secret_key=nFTXlO7nsPNNUj59tFE21Py9tOO8fwOtHNsr3YwN region=eu-central-1\"\n</code></pre> <p>Uses S3 bucket for storing backups (by default AWS but own instance can be specified eg. Minio).</p> <p>Note</p> <p>There can be only one upload provider defined per app, using BACKUP_PROVIDER environemnt variable. It's type is guessed by using <code>name</code>, in this case <code>name=s3</code>. Params must be included in value, splited by single space for example \"value1=1 value2=foo\".</p>"},{"location":"providers/s3/#params","title":"Params","text":"Name Type Description Default name string[requried] Must be set literaly to string <code>s3</code> to use S3. - bucket_name string[requried] Your globally unique bucket name. - bucket_upload_path string[requried] Prefix that every created backup will have, for example if it is equal to <code>my_ogion_instance_1</code>, paths to backups will look like <code>my_ogion_instance_1/your_backup_target_eg_postgresql/file123.age</code>. Usually this should be something unique for this ogion instance, for example <code>k8s_foo_ogion</code>. - endpoint string S3 endpoint. s3.amazonaws.com secure string If set to <code>false</code>, connect to endpoint under http. true region string Bucket region. null access_key string User access key id, see Resources below. null secret_key string User access key secret, see Resources below. null"},{"location":"providers/s3/#examples","title":"Examples","text":"<pre><code># 1. AWS Bucket pets-bucket\nBACKUP_PROVIDER='name=s3 bucket_name=pets-bucket bucket_upload_path=pets_ogion access_key=AKIAU5JB5UQDL8C3K6UP secret_key=nFTXlO7nsPNNUj59tFE21Py9tOO8fwOtHNsr3YwN region=eu-central-1'\n\n# 2. AWS Bucket birds with other region\nBACKUP_PROVIDER='name=s3 bucket_name=birds bucket_upload_path=birds_ogion access_key=AKIAU5JB5UQDL8C3K6UP secret_key=nFTXlO7nsPNNUj59tFE21Py9tOO8fwOtHNsr3YwN region=us-east-1'\n\n# 3. Min.io instance \nBACKUP_PROVIDER='name=s3 endpoint=my-min.io.com bucket_name=pets-bucket bucket_upload_path=pets_ogion access_key=AKIAU5JB5UQDL8C3K6UP secret_key=nFTXlO7nsPNNUj59tFE21Py9tOO8fwOtHNsr3YwN region=default'\n\n# 4. Min.io localhost instance under http and no auth\nBACKUP_PROVIDER='name=s3 endpoint=localhost:9000 bucket_name=pets-bucket bucket_upload_path=pets_ogion secure=false'\n</code></pre>"},{"location":"providers/s3/#resources","title":"Resources","text":""},{"location":"providers/s3/#bucket-and-iam-walkthrough","title":"Bucket and IAM walkthrough","text":"<p>https://docs.aws.amazon.com/AmazonS3/latest/userguide/walkthrough1.html</p>"},{"location":"providers/s3/#giving-iam-user-required-permissions","title":"Giving IAM user required permissions","text":"<p>Assuming your bucket name is <code>my_bucket_name</code> and upload path <code>test-upload-path</code>, 3 permissions are needed for IAM user (s3:ListBucket, s3:PutObject, s3:DeleteObject):</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"AllowList\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"s3:ListBucket\",\n      \"Resource\": \"arn:aws:s3:::my_bucket_name\",\n      \"Condition\": {\n        \"StringLike\": {\n          \"s3:prefix\": \"test-upload-path/*\"\n        }\n      }\n    },\n    {\n      \"Sid\": \"AllowPutGetDelete\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:PutObject\", \"s3:DeleteObject\"],\n      \"Resource\": \"arn:aws:s3:::my_bucket_name/test-upload-path/*\"\n    }\n  ]\n}\n</code></pre> <p> </p>"}]}